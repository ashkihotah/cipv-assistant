Detecting toxicity in online conversations is a critical NLP challenge, especially in private, intimate dialogues where data is scarce and context is paramount. We address this by introducing a novel pipeline to generate synthetic Italian chats, annotated with fine-grained, message-level continuous toxicity scores and human-readable explanations. Leveraging this dataset, we conduct a comprehensive empirical study across three tasks: chat-level classification, message-level regression and abstractive explanation generation. We've also performed comparative statistical analyses to rigorously evaluate standard classification problem modeling against a more nuanced regression approach to the toxic detection task. Our results reveal a surprising performance plateau, with diverse models achieving statistically similar peak F1-scores (~0.78 for multiclass, ~0.87 for binary). This suggests that performance is currently limited by the task's inherent ambiguity and data characteristics rather than model complexity. This work's primary contributions are a replicable, psychologically-grounded data generation methodology and a rigorous analysis of modeling strategies for this nuanced NLP challenge.
