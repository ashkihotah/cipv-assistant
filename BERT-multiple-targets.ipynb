{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../input/requirements/requirements.txt\n",
    "# !pip install evaluate\n",
    "# !pip install rouge_score\n",
    "# !pip install bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02653c6f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from typing import Optional, List, Dict, Union, Tuple\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertForSequenceClassification, \n",
    "    BertConfig,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4792a16",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed5d9b",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "MODEL_CHECKPOINT = \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "\n",
    "WITH_TOKEN_TYPE_IDS = True\n",
    "WITH_SEP_TOKENS = True\n",
    "\n",
    "TRAIN_MODE = \"train_no_optuna\"\n",
    "# TRAIN_MODE = \"train_with_optuna\"\n",
    "TEST_MODE = \"test_no_optuna\"\n",
    "# TEST_MODE = \"test_with_optuna\"\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "SAVE_TOTAL_LIMIT = 3\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "EARLY_STOPPING_PATIENCE = 2\n",
    "WARMUP_PERCENTAGE = 0.1\n",
    "WEIGHT_DECAY = 0.01 # int the 0 to 0.1 range\n",
    "BODY_LR = 3e-5\n",
    "HEAD_LR = 1.5e-4\n",
    "\n",
    "OPTUNA_TRAIN_TRIALS=2\n",
    "OPTUNA_TEST_TRIALS=2\n",
    "PRUNER_WARMUP_STEPS=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1663e",
   "metadata": {},
   "source": [
    "## Paths Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7571b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# ==== LOCAL SETTINGS ====\n",
    "PATH = os.path.join(\".\", \"out\", \"datasets\", \"cipv-chats-toxicity\", \"chats\") # , \"gen2\", \"chats\"\n",
    "OUT_DIR = os.path.join(\".\", \"out\", \"models\", \"BERT\", timestamp)\n",
    "\n",
    "# ==== KAGGLE SETTINGS ====\n",
    "# PATH = os.path.join(os.sep, \"kaggle\", \"input\", \"cipv-chats-sentiment\")\n",
    "# OUT_DIR = os.path.join(os.sep, \"kaggle\", \"working\", timestamp)\n",
    "\n",
    "RESULTS_PATH = os.path.join(OUT_DIR, \"results\")\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317b035",
   "metadata": {},
   "source": [
    "## Kaggle Specific Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab208e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(os.path.join(os.sep, \"kaggle\", \"working\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_file_path = \"/kaggle/working/out-EuclideanLoss-MSELoss-single_sep_False\"\n",
    "# shutil.make_archive(zip_file_path, 'zip', zip_file_path)\n",
    "# shutil.rmtree(zip_file_path)\n",
    "# os.remove(zip_file_path + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460e1f9",
   "metadata": {},
   "source": [
    "## Plots Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f95671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(log_history, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Extract logs with 'epoch', 'loss', and 'eval_loss'\n",
    "    train_logs = [log for log in log_history if 'epoch' in log and 'loss' in log]\n",
    "    eval_logs = [log for log in log_history if 'epoch' in log and 'eval_loss' in log]\n",
    "\n",
    "    # Convert to DataFrames for easy grouping\n",
    "    train_df = DataFrame(train_logs)\n",
    "    eval_df = DataFrame(eval_logs)\n",
    "\n",
    "    # Group by epoch and compute mean loss per epoch\n",
    "    train_epoch_loss = train_df.groupby('epoch')['loss'].mean()\n",
    "    eval_epoch_loss = eval_df.groupby('epoch')['eval_loss'].mean()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(train_epoch_loss.index, train_epoch_loss.values, 'g-o', label='Train Loss')\n",
    "    plt.plot(eval_epoch_loss.index, eval_epoch_loss.values, 'c-o', label='Eval Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Losses Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"learning_curve.png\"))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6dd6dc",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687531f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForRegression(BertForSequenceClassification):\n",
    "    \"\"\"\n",
    "    A BERT regression model that leverages the pretrained classifier head.\n",
    "\n",
    "    Instead of replacing the original classifier, this model keeps it and adds\n",
    "    a new linear layer on top (`self.regression_head`). This allows the model\n",
    "    to use the features learned by the original classification head for the new\n",
    "    regression task.\n",
    "\n",
    "    The final output is passed through a Tanh function in the forward pass to\n",
    "    squash the polarity prediction to the [-1, 1] range.\n",
    "\n",
    "    This model is fully compatible with the Hugging Face Trainer API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: BertConfig, cls_token_id: int = None):\n",
    "        super().__init__(config)\n",
    "        if cls_token_id is None:\n",
    "            raise ValueError(\"cls_token_id must be provided to identify the CLS token in input_ids.\")\n",
    "        self.cls_token_id = cls_token_id\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        # output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        \"\"\"\n",
    "        Forward pass for the regression model.\n",
    "\n",
    "        Args:\n",
    "            labels (`torch.FloatTensor` of shape `(batch_size,)`, *optional*):\n",
    "                Labels for computing the Mean Squared Error regression loss.\n",
    "\n",
    "        Returns:\n",
    "            `transformers.modeling_outputs.SequenceClassifierOutput`: An object\n",
    "            containing the loss (if labels are provided), logits (the final\n",
    "            polarity predictions), hidden states, and attentions.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # Step 1: Get the standard BERT model outputs\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,  # output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.hidden_states  # tuple: (layer0, layer1, ..., last_layer)\n",
    "        last_hidden_state = hidden_states[-1]  # shape: (batch_size, seq_len, hidden_size)\n",
    "        cls_mask = (input_ids == self.cls_token_id)  # shape: (batch_size, seq_len)\n",
    "\n",
    "        # Step 2: Pass through the original dropout and classifier layers\n",
    "        # This leverages the pretrained classifier as a feature extractor.\n",
    "        output = self.dropout(last_hidden_state[cls_mask])\n",
    "        output = self.classifier(output)\n",
    "        logits = torch.tanh(output).squeeze()\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Flatten labels and create a mask for non-padded labels\n",
    "            flat_labels = labels.view(-1)\n",
    "            label_mask = flat_labels != -100\n",
    "            \n",
    "            # Filter both logits and labels to only include non-padded items\n",
    "            # The number of True values in cls_mask should equal the number of non-padded labels\n",
    "            filtered_logits = logits\n",
    "            filtered_labels = flat_labels[label_mask]\n",
    "\n",
    "            # Ensure the number of predictions matches the number of valid labels\n",
    "            # if filtered_logits.shape[0] != filtered_labels.shape[0]:\n",
    "            #     raise RuntimeError(\n",
    "            #         f\"Mismatch between number of CLS tokens ({filtered_logits.shape[0]}) \"\n",
    "            #         f\"and non-padded labels ({filtered_labels.shape[0]}). \"\n",
    "            #         \"Check data collator and input data.\"\n",
    "            #     )\n",
    "\n",
    "            loss = F.mse_loss(filtered_logits, filtered_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "class DataCollatorForPolarity(DataCollatorWithPadding):\n",
    "    \"\"\"\n",
    "    Data collator for polarity regression tasks.\n",
    "\n",
    "    This collator extends DataCollatorWithPadding to handle a 'polarity' field\n",
    "    in the input features. It extracts the polarity values, converts them to a\n",
    "    torch.FloatTensor, and adds them to the batch dictionary under the key 'labels'.\n",
    "\n",
    "    This makes it compatible with models that expect a `labels` argument for\n",
    "    loss calculation, such as the `BertForRegression` model.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, padding=True, max_length=None, pad_to_multiple_of=None):\n",
    "        super().__init__(tokenizer, padding=padding, max_length=max_length, pad_to_multiple_of=pad_to_multiple_of)\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Collates a batch of features.\n",
    "\n",
    "        Args:\n",
    "            features (List[Dict[str, Union[List[int], torch.Tensor]]]): A list of\n",
    "                feature dictionaries. Each dictionary must contain tokenized inputs\n",
    "                (e.g., 'input_ids') and a 'polarity' key with a float value.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: A dictionary containing the padded batch of\n",
    "                inputs and a 'labels' tensor.\n",
    "        \"\"\"\n",
    "        # Separate the polarities from the features that need padding\n",
    "        label_tensors = [feature.pop(\"labels\") for feature in features]\n",
    "        \n",
    "        # Use the parent class to handle padding of 'input_ids', 'attention_mask', etc.\n",
    "        batch = super().__call__(features)\n",
    "        \n",
    "        padded_labels = pad_sequence(\n",
    "            label_tensors,\n",
    "            batch_first=True,\n",
    "            padding_value=-100  # Standard ignore_index for loss calculation\n",
    "        )\n",
    "            \n",
    "        batch[\"labels\"] = torch.tensor(padded_labels, dtype=torch.float)\n",
    "        \n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adebe2",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_add(dataset, messages, couple_dir):\n",
    "    all_names = [msg.group(\"name\") for msg in messages]\n",
    "    if WITH_TOKEN_TYPE_IDS:\n",
    "        unique_names = list(set(all_names))\n",
    "        all_messages = [ f\"[{unique_names.index(all_names[i])}]\" + msg.group(\"name_content\") for i, msg in enumerate(messages)]\n",
    "        if WITH_SEP_TOKENS:\n",
    "            input_chat = (\"[CLS][SEP]\" + \"\\n\").join(all_messages) + \"[CLS]\"\n",
    "        else:\n",
    "            input_chat = (\"[CLS]\" + \"\\n\").join(all_messages) + \"[CLS]\"\n",
    "    else:\n",
    "        input_chat = (\"[CLS]\" + \"\\n\").join(all_messages) + \"[CLS]\"\n",
    "\n",
    "\n",
    "    dataset['chats'].append(input_chat)\n",
    "    dataset['polarities'].append([float(msg.group(\"polarity\")) for msg in messages])\n",
    "    dataset['user_ids'].append(couple_dir)\n",
    "    dataset['msgs_lengths'].append(len(messages))\n",
    "\n",
    "def load_dataset(path):\n",
    "    # msgs_regex = re.compile(r\"(?P<message>(?P<timestamp>\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d) \\|? ?(?P<name_content>(?P<name>.+):\\n(?P<content>.+))\\n+Polarity: (?P<polarity>[-+]?\\d\\.?\\d?\\d?)\\n\\[(?P<tag_explanation>(?P<tag>Tag: .+)\\n?Spiegazione: (?P<explanation>.+))\\])\")\n",
    "    msgs_regex = re.compile(r\"(?P<message>\\(?(?P<timestamp>\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d)\\)? ?\\|? ?(?P<name_content>(?P<name>.+):\\n?\\s?(?P<content>.+))\\n?\\s?Polarity: (?P<polarity>(?:-?|\\+?)\\d\\.?\\d?\\d?))\")\n",
    "    dataset = {\n",
    "        \"chats\": [],\n",
    "        \"polarities\": [],\n",
    "        \"user_ids\": [],\n",
    "        \"msgs_lengths\": [],\n",
    "    }\n",
    "    skipped = 0\n",
    "    model_dirs = os.listdir(path)\n",
    "    for model_dir in tqdm(model_dirs, desc=\"ðŸ“‚ Loading Dataset\"):\n",
    "        model_dir_path = os.path.join(path, model_dir)\n",
    "        couple_dirs = os.listdir(model_dir_path)\n",
    "        for couple_dir in tqdm(couple_dirs, desc=f\"ðŸ“‚ Loading Directory: {model_dir_path}\"):\n",
    "            couple_dir_path = os.path.join(model_dir_path, couple_dir)\n",
    "            files = os.listdir(couple_dir_path)\n",
    "            for file in files:\n",
    "                with open(os.path.join(couple_dir_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    chat = f.read()\n",
    "                    messages = list(msgs_regex.finditer(chat))\n",
    "                    if len(messages) > 0: # checks if there are matched messages\n",
    "                        simple_add(dataset, messages, couple_dir)\n",
    "                    else:\n",
    "                        skipped += 1\n",
    "                        print(f\"No messages found in file: {os.path.join(couple_dir_path, file)}\")\n",
    "                        \n",
    "    return dataset, skipped\n",
    "\n",
    "dataset, skipped = load_dataset(PATH)\n",
    "dataset = Dataset.from_dict(dataset)\n",
    "print(f\"Skipped: {skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(dataset):\n",
    "    print(dataset)\n",
    "    # For each field, print the first entry\n",
    "    for field in dataset.features:\n",
    "        print(f\"{field}: {dataset[0][field]}\\n\")\n",
    "\n",
    "print_dataset_info(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505aa33",
   "metadata": {},
   "source": [
    "# Pre-Processing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02488f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "if WITH_TOKEN_TYPE_IDS:\n",
    "    tokenizer.add_special_tokens({\n",
    "        \"additional_special_tokens\": [\"[0]\", \"[1]\"]\n",
    "    })\n",
    "    id_0 = tokenizer.convert_tokens_to_ids(\"[0]\")\n",
    "    id_1 = tokenizer.convert_tokens_to_ids(\"[1]\")\n",
    "    print(f\"Special tokens added: {id_0} for [0], {id_1} for [1]\")\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized_chats = tokenizer(\n",
    "        examples['chats'],\n",
    "        # padding='max_length',\n",
    "        # truncation=True,\n",
    "        # max_length=512,\n",
    "        # return_tensors='pt',\n",
    "        add_special_tokens=False # Skip special tokens in the target text\n",
    "    )\n",
    "    tokenized_chats[\"labels\"] = examples[\"polarities\"]\n",
    "    tokenized_chats[\"user_ids\"] = examples[\"user_ids\"]\n",
    "    tokenized_chats[\"msgs_lengths\"] = examples[\"msgs_lengths\"]\n",
    "\n",
    "    if WITH_TOKEN_TYPE_IDS:\n",
    "        tkn_type = 0  # Default token type\n",
    "        for i, sample in enumerate(tokenized_chats['input_ids']):\n",
    "            for j, tkn in enumerate(sample):\n",
    "                if tkn == id_0:\n",
    "                    tkn_type = 0\n",
    "                    # remove the special token at current position\n",
    "                    tokenized_chats['input_ids'][i].pop(j)\n",
    "                    tokenized_chats['attention_mask'][i].pop(j)\n",
    "                    tokenized_chats['token_type_ids'][i].pop(j)\n",
    "                elif tkn == id_1:\n",
    "                    tkn_type = 1\n",
    "                    # remove the special token at current position\n",
    "                    tokenized_chats['input_ids'][i].pop(j)\n",
    "                    tokenized_chats['attention_mask'][i].pop(j)\n",
    "                    tokenized_chats['token_type_ids'][i].pop(j)\n",
    "                tokenized_chats['token_type_ids'][i][j] = tkn_type\n",
    "\n",
    "    return tokenized_chats\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    # batch_size=1000,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "print_dataset_info(tokenized_dataset)\n",
    "# print(tokenized_dataset)\n",
    "\n",
    "# remove the special tokens from the tokenizer\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(tokenized_dataset)\n",
    "\n",
    "more_than_1024_input_mask = df['input_ids'].apply(lambda x: len(x) > 1024)\n",
    "more_than_512_input_mask = df['input_ids'].apply(lambda x: len(x) > 512)\n",
    "\n",
    "# print(f\"Tokenized dataset:\\n{df.head()}\")\n",
    "print(\"input_ids token length statistics:\")\n",
    "print(f\"Number of samples with more than 1024 tokens: {len(df[more_than_1024_input_mask])}\")\n",
    "print(f\"Number of samples with more than 512 tokens: {len(df[more_than_512_input_mask])}\")\n",
    "\n",
    "# plots histograms for input_ids and labels with different colors in a single plot\n",
    "# with semi-transparent bars in order to visualize overlaps\n",
    "# with 1024 + 1 bins where the last bin is for samples with more than 1024 tokens\n",
    "\n",
    "input_ds_token_lengths = df['input_ids'].apply(lambda x: len(x))\n",
    "\n",
    "input_ds_token_lengths.hist(bins=input_ds_token_lengths.max(), edgecolor='blue', alpha=0.5, label='Input Chats')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Token Length Distribution')\n",
    "plt.legend()\n",
    "# plt.savefig(os.path.join(OUT_DIR, \"token_and_message_length_distribution.png\"))\n",
    "plt.show()\n",
    "\n",
    "# min_msgs = df['msgs_lengths'].min()\n",
    "max_msgs = df['msgs_lengths'].max()\n",
    "df['msgs_lengths'].hist(\n",
    "    bins=range(max_msgs + 1),  # +2 so last bin includes max\n",
    "    edgecolor='black',\n",
    "    label='Messages Lengths',\n",
    "    align='left'\n",
    ")\n",
    "plt.xlabel('Number of Messages')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Messages Length Distribution')\n",
    "plt.legend()\n",
    "# plt.savefig(os.path.join(OUT_DIR, \"messages_length_distribution.png\"))\n",
    "plt.yscale('log')\n",
    "plt.xticks(range(max_msgs + 1))\n",
    "plt.show()\n",
    "\n",
    "# Remove all samples with more than 1024 tokens in input_ids and labels\n",
    "df = df[~more_than_512_input_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c0867",
   "metadata": {},
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Users in dataset: {df['user_ids'].nunique()}\")\n",
    "print(f\"Dataset size: {len(df)}\\n\")\n",
    "\n",
    "df.drop(columns=['msgs_lengths'], inplace=True)\n",
    "\n",
    "# Split the dataset into train, test, and eval sets using user_ids grouped examples\n",
    "grouped = df.groupby('user_ids')#.size().reset_index(name='counts')\n",
    "user_ids = list(grouped.groups.keys()) #[:10]\n",
    "# df = df[df['user_ids'].isin(user_ids)]\n",
    "\n",
    "train_ids, test_ids = train_test_split(user_ids, test_size=TEST_SIZE, random_state=42)\n",
    "train_ids, eval_ids = train_test_split(train_ids, test_size=TEST_SIZE, random_state=42)\n",
    "tokenized_train_set = df[df['user_ids'].isin(train_ids)]\n",
    "tokenized_test_set = df[df['user_ids'].isin(test_ids)]\n",
    "tokenized_eval_set = df[df['user_ids'].isin(eval_ids)]\n",
    "\n",
    "# Prints how many users are in each set\n",
    "print(f\"Users in train set: {tokenized_train_set['user_ids'].nunique()}\")\n",
    "print(f\"Users in test set: {tokenized_test_set['user_ids'].nunique()}\")\n",
    "print(f\"Users in eval set: {tokenized_eval_set['user_ids'].nunique()}\\n\")\n",
    "\n",
    "# Remove the 'user_ids' column from the train, test, and eval sets\n",
    "tokenized_train_set = tokenized_train_set.drop(columns=['user_ids'])\n",
    "tokenized_test_set = tokenized_test_set.drop(columns=['user_ids'])\n",
    "tokenized_eval_set = tokenized_eval_set.drop(columns=['user_ids'])\n",
    "\n",
    "tokenized_train_set = tokenized_train_set.reset_index(drop=True)\n",
    "tokenized_test_set = tokenized_test_set.reset_index(drop=True)\n",
    "tokenized_eval_set = tokenized_eval_set.reset_index(drop=True)\n",
    "\n",
    "tokenized_train_set = Dataset.from_pandas(tokenized_train_set)\n",
    "tokenized_test_set = Dataset.from_pandas(tokenized_test_set)\n",
    "tokenized_eval_set = Dataset.from_pandas(tokenized_eval_set)\n",
    "\n",
    "print(f\"Train set size: {len(tokenized_train_set)}\")z\n",
    "print(f\"Test set size: {len(tokenized_test_set)}\")\n",
    "print(f\"Eval set size: {len(tokenized_eval_set)}\\n\")\n",
    "\n",
    "# Set the format to PyTorch tensors\n",
    "tokenized_train_set.set_format(\"torch\")\n",
    "tokenized_test_set.set_format(\"torch\")\n",
    "tokenized_eval_set.set_format(\"torch\")\n",
    "\n",
    "print_dataset_info(tokenized_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dbc79",
   "metadata": {},
   "source": [
    "# Training BERT for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65258e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForPolarity(tokenizer=tokenizer)\n",
    "\n",
    "model = BertForRegression.from_pretrained(\n",
    "    MODEL_CHECKPOINT, \n",
    "    num_labels=1, # our task is regression (num_labels=1).\n",
    "    cls_token_id=tokenizer.cls_token_id,  # Pass the CLS token ID to the model\n",
    ")\n",
    "\n",
    "# loaded_model = BertForRegression.from_pretrained(\n",
    "#     \".\\\\out\\\\models\\\\BERT\\\\2025-07-31_09-53-11\\\\checkpoint-40\",\n",
    "#     num_labels=1,  # our task is regression (num_labels=1).\n",
    "#     cls_token_id=tokenizer.cls_token_id,  # Pass the CLS token ID to the model\n",
    "# ).to(DEVICE)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=BODY_LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_PERCENTAGE,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=SAVE_TOTAL_LIMIT,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    dataloader_num_workers=NUM_WORKERS,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_set,\n",
    "    eval_dataset=tokenized_eval_set,\n",
    "    # tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "plot_losses(trainer.state.log_history, RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363d98d",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79955a26",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference(model, chat):\n",
    "#     tokenized_chat = tokenizer(\n",
    "#         chat,\n",
    "#         truncation=True,\n",
    "#         max_length=512,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     tokenized_chat = {k: v.to(DEVICE) for k, v in tokenized_chat.items()}\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**tokenized_chat)\n",
    "    \n",
    "#     logits = outputs.logits.squeeze()\n",
    "#     return logits\n",
    "\n",
    "# # Example inference\n",
    "# chat = '''\n",
    "# Mauro:\n",
    "# Ei, come va?\n",
    "# Maria:\n",
    "# Ciao Mauro! Tutto bene, grazie! E tu?\n",
    "# Mauro:\n",
    "# Tutto ok, grazie! Che fai di bello oggi?\n",
    "# Maria:\n",
    "# Sinceramente non lo so, ho un po' di cose da fare ma non so da dove cominciare. Tu che fai?\n",
    "# '''\n",
    "# logits = inference(model, chat)\n",
    "# print(f\"Inference logits: {logits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfed4af",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa89dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.evaluate(\n",
    "    eval_dataset=tokenized_test_set,\n",
    "    metric_key_prefix=\"test\"\n",
    ")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "with open(os.path.join(RESULTS_PATH, \"test_metrics.txt\"), \"w\") as f:\n",
    "    for key, value in test_metrics.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
