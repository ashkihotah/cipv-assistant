{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61d148f",
   "metadata": {},
   "source": [
    "Chat Toxicity Classification - Modelli a confronto\n",
    "=================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cf123",
   "metadata": {},
   "source": [
    "Sezione 1: Preprocessing e setup\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f67ec1",
   "metadata": {},
   "source": [
    "# TO-DO: estrarre la media delle polarità e soglie di classificazione \n",
    "###     Toxic: [-1,-0.35],  \n",
    "###     Neutral: [-0.35, +0.35],  \n",
    "###     Healty: [+0.35, +1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48edf82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset di esempio (puoi sostituirlo con il tuo)\n",
    "texts = [\n",
    "    \"Ciao Marco! Spero tu stia avendo una buona mattinata. Volevo avvisarti che oggi ho una giornata super intensa con il progetto per il cliente di New York. Devo concentrarmi al massimo e potrei non essere molto reattiva sui messaggi.\",\n",
    "    \"Ciao Sofia! Ottima notizia che stai a pieno ritmo con il progetto. Capisco perfettamente l'importanza di concentrarsi su lavori così grossi. Prenditi tutto il tempo che ti serve. Il tuo focus è fondamentale.\",\n",
    "    \"Sofia, ho visto che hai lasciato le luci accese in salotto tutta la notte. È uno spreco di soldi e non va bene. Dobbiamo stare più attenti.\",\n",
    "    \"La solita storia. Le 'consegne'. Il tuo lavoro non è una scusa per trascurare la casa e le nostre cose. Sei sempre dietro a quei disegni, ma le priorità sembrano non esistere per te.\",\n",
    "    \"Sofia, questo weekend i miei genitori verranno a Milano. Vorrei che tu li incontrassi. È un passo importante per me, spero tu possa esserci. Voglio che vedano che sono con una persona seria e che è la scelta giusta per me.\",\n",
    "    \"Non c'è motivo di essere nervosa, Sofia. L'importante è che tu sia te stessa, ma ricorda, la mia famiglia è tradizionale. Sono i tuoi primi incontri con i miei, giusto? Non parlare troppo di questioni 'artistiche' che non capirebbero. E non essere troppo sentimentale.\",\n",
    "    \"Alessio, wow! Hai già trovato un posto e hai preparato tutto? Sono così emozionata all'idea di andare a vivere insieme! Mi fa sentire che stiamo davvero costruendo qualcosa di importante e concreto. Via dei Fossi è perfetta, è un quartiere che amo! Certo che sono disponibile per il sopralluogo, non vedo l'ora! Grazie per aver pensato a tutto questo, è bellissimo. 🥰\",\n",
    "    \"Non mi piace il tuo modo di fare, sei sempre così arrogante e presuntuosa. Non capisci mai le cose al volo e devi sempre essere corretta.\",\n",
    "    \"Non capisco perché tu debba sempre criticare tutto quello che faccio. Non hai mai niente di buono da dire, sei sempre negativa.\",\n",
    "    \"Sei davvero insopportabile, non riesco a sopportare il tuo modo di fare. Sei sempre così piena di te e non ascolti mai gli altri.\",\n",
    "    \"Ti voglio bene, sei una persona speciale per me. Spero che tu possa capire quanto ti apprezzo e quanto sei importante nella mia vita.\",\n",
    "]\n",
    "labels = [0, 0, 1, 1, 0, 1, 0, 1 ,1, 1, 0]  # 1 = tossico, 0 = non tossico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e4182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5ab2f",
   "metadata": {},
   "source": [
    "# Stemmers and Lemmatizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import stanza\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851bec0",
   "metadata": {},
   "source": [
    "1) Stemming: SnowballStemmer di NLTK\n",
    "\n",
    "✅ Vantaggi:\n",
    "- Veloce\n",
    "\n",
    "- Nessuna dipendenza da modelli esterni\n",
    "\n",
    "- Facile da usare\n",
    "\n",
    "❌ Svantaggi:\n",
    "- Approccio meccanico, senza analisi grammaticale\n",
    "\n",
    "- Può troncare male alcune parole\n",
    "\n",
    "- Produce radici non leggibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb95afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class SnowballPreprocessor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer(\"italian\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join([self.stemmer.stem(w) for w in text.split()]) for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78f352",
   "metadata": {},
   "source": [
    "2) Lemmatizer: spaCy Lemmatizer di spaCy\n",
    "\n",
    "✅ Vantaggi:\n",
    "- Precisa: usa morfologia e POS tagging\n",
    "\n",
    "- Restituisce parole vere e leggibili\n",
    "\n",
    "- Tiene conto del contesto (in parte)\n",
    "\n",
    "❌ Svantaggi:\n",
    "- Più lenta\n",
    "\n",
    "- Serve scaricare il modello it_core_news_sm\n",
    "\n",
    "- Rimuove meno \"rumore\" rispetto allo stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_spacy = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "class SpacyLemmatizer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [' '.join([token.lemma_ for token in nlp_spacy(text) \n",
    "                          if not token.is_punct and not token.is_space]) \n",
    "                for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff427e2d",
   "metadata": {},
   "source": [
    "3) Lemmatizer: Stanza Lemmatizer di Stanza\n",
    "\n",
    "✅ Vantaggi:\n",
    "- Ancora più accurata di spaCy in certi contesti\n",
    "\n",
    "- Buona copertura grammaticale\n",
    "\n",
    "❌ Svantaggi:\n",
    "- Molto lenta\n",
    "\n",
    "- Richiede inizializzazione pesante\n",
    "\n",
    "- Non adatta a pipeline veloci o batch di grandi dimensioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4258737",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('it')\n",
    "nlp_stanza = stanza.Pipeline(lang='it', processors='tokenize,pos,lemma', use_gpu=True) # use_gpu=True se disponibile per velocizzare\n",
    "\n",
    "class StanzaLemmatizer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed = []\n",
    "        for text in X:\n",
    "            doc = nlp_stanza(text)\n",
    "            lemmi = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "            transformed.append(' '.join(lemmi))\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed159fb",
   "metadata": {},
   "source": [
    "## Tokenizer personalizzato per parole + punteggiatura + emoji\n",
    "Questo tokenizer è stato introdotto per **preservare punteggiatura ed emoji**, elementi fondamentali per cogliere **toni emotivi e segnali di tossicità** nelle chat.  \n",
    "Inoltre, mantiene le **parole completamente in MAIUSCOLO**, che possono indicare **aggressività o urla**, normalizzando in lowercase solo il resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ba0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex che cattura parole, punteggiatura e emoji unicode\n",
    "def custom_tokenizer(text):\n",
    "    emoji_pattern = r'[\\U00010000-\\U0010ffff]'          # emoji Unicode\n",
    "    word_punct = r'\\w+|[^\\w\\s]'                         # parole + punteggiatura\n",
    "    combined = f'{emoji_pattern}|{word_punct}'\n",
    "    tokens = re.findall(combined, text)\n",
    "\n",
    "    processed_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isupper() and len(token) > 1:\n",
    "            # Mantieni MAIUSCOLO solo se tutta la parola è in maiuscolo\n",
    "            processed_tokens.append(token)\n",
    "        else:\n",
    "            # Altrimenti normalizza in minuscolo\n",
    "            processed_tokens.append(token.lower())\n",
    "    \n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposta se usare o meno le stopwords italiane\n",
    "USE_STOPWORDS = False  # Cambia in False per disattivarle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ca218",
   "metadata": {},
   "source": [
    "# TO-DO: Prova anche a personalizzare le stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4608c0",
   "metadata": {},
   "source": [
    "Breve spiegazione:\n",
    "- Stopwords = parole molto comuni (es: \"il\", \"e\", \"di\").\n",
    "- Se le rimuovi, il modello si concentra sulle parole più informative.\n",
    "- Se le mantieni, a volte possono aiutare (es: \"non\" in \"non mi piace\").\n",
    "\n",
    "Stopwords: rimuoverle o no?\n",
    "\n",
    "✅ Motivi per tenerle\n",
    "Parole funzionali possono cambiare il tono\n",
    "\n",
    "- Frasi come:\n",
    "“non ti sopporto più” → “non” è fondamentale.\n",
    "“sei sempre contro di me” → “sempre”, “contro” possono essere segnali chiave.\n",
    "\n",
    "- In frasi brevi e chat reali, il contenuto tossico può dipendere da dettagli sottili che le stopwords aiutano a mantenere.\n",
    "\n",
    "- Stai valutando il tono globale della chat, quindi anche parole come “ma”, “però”, “non”, “perché” potrebbero segnalare conflitto o sarcasmo.\n",
    "\n",
    "❌ Motivi per rimuoverle\n",
    "- Riducono il rumore nei modelli BoW/TF-IDF: parole tipo “il”, “di”, “e”, “la” non portano informazione rilevante.\n",
    "\n",
    "- Dimensionalità più bassa → modelli più leggeri e meno prone all’overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f337e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_setting = 'italian' if USE_STOPWORDS else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5835cf",
   "metadata": {},
   "source": [
    "Sezione 2: Logistic Regression con TF-IDF\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('tfidf', TfidfVectorizer(stop_words=stopwords_setting,\n",
    "                                    tokenizer=custom_tokenizer,\n",
    "                                    token_pattern=None,          # disattiva il tokenizer interno di scikit-learn\n",
    "                                    lowercase=False)),           # Disattiva lowercase automatico: lo gestiamo noi nel tokenizer\n",
    "        ('clf', LogisticRegression(random_state=42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, preproc in {\n",
    "    \"Snowball\": SnowballPreprocessor(),\n",
    "    \"spaCy\": SpacyLemmatizer(),\n",
    "    \"Stanza\": StanzaLemmatizer()\n",
    "}.items():\n",
    "    print(f\"\\n Valutazione con {name}\")\n",
    "    pipeline_logreg = build_pipeline(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63dbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of TfidfVectorizer usage\n",
    "# a=TfidfVectorizer(stop_words=stopwords_setting, min_df=1, max_df=0.9)\n",
    "# # print first 10 samples of the matrix\n",
    "# print(a.fit_transform(X_train).toarray()[:10])\n",
    "# # print first 10 words of the vocabulary\n",
    "# print(a.vocabulary_)\n",
    "# # print size of the vocabulary\n",
    "# print(len(a.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a66ba6",
   "metadata": {},
   "source": [
    "- `TfidfVectorizer` è una classe di scikit-learn che trasforma il testo in una matrice di frequenze TF-IDF.\n",
    "\n",
    "Iperparametri di TfidfVectorizer\n",
    "\n",
    "- stopwords_setting: serve per specificare se escludere le stopwords italiane o meno.\n",
    "- min_df=1: include tutte le parole che compaiono almeno in un documento.\n",
    "- max_df=0.9: esclude parole troppo comuni (es. se appaiono nel 90% dei documenti o più).\n",
    "- norm='l2' (default): normalizzazione euclidea → la somma dei quadrati delle componenti del vettore sarà 1.\n",
    "\n",
    "- TfidfVectorizer normalizza ogni sample (cioè ogni documento):\n",
    "\n",
    "A cosa serve l2\n",
    "- Aiuta a ridurre l’influenza dei documenti lunghi (che altrimenti avrebbero valori TF-IDF più alti solo perché hanno più parole).\n",
    "- Rende i vettori più comparabili tra loro (molto importante per modelli lineari come LogisticRegression\n",
    "\n",
    "Vantaggi di L2\n",
    "- Densità e stabilità: L2 distribuisce il peso più uniformemente tra le feature, senza azzerare valori.\n",
    "- Ottima per modelli lineari: modelli come Logistic Regression, SVM, spesso lavorano meglio con vettori normalizzati L2.\n",
    "- Maggiore sensibilità alle differenze più piccole: perché somma quadratica enfatizza i valori più alti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b342c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lg = {\n",
    "    'clf__max_iter': [1000, 10000],                     # Iterazioni per la convergenza\n",
    "    'clf__solver': ['lbfgs'],                   # Solver stabile per l2\n",
    "    'clf__penalty': ['l2'], \n",
    "    'clf__C': [0.1, 1, 10],                     # Molto importante: forza della regolarizzazione (più basso = più reg.)\n",
    "    'tfidf__max_df': [0.7, 0.85, 1.0],          # Importante: esclude parole troppo frequenti\n",
    "    'tfidf__min_df': [1],                       # Importante: esclude parole troppo rare (provare ad aumentare con dataset più grandi)\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]        # Importante: n-gram per catturare frasi brevi\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88888298",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531a40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "Best params: {'clf__C': 0.1, 'clf__max_iter': 1000, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'tfidf__max_df': 0.7, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)}\n",
      "Best Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline_logreg, param_grid_lg, cv=2, scoring='recall', n_jobs=-1, verbose=1)   \n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best Recall:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb095d",
   "metadata": {},
   "source": [
    "# TO-DO: cercare combinazione tra recall e precision e usare heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f893ec",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ceab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (TF-IDF) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_logreg = grid.predict(X_test)\n",
    "print(\"\\n=== Logistic Regression (TF-IDF) ===\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16a48c",
   "metadata": {},
   "source": [
    "- scoring='recall',        # Metrica di valutazione\n",
    "- cv=5,                    # Numero di fold per la cross-validation\n",
    "- n_jobs=-1,               # Usa tutti i core della CPU per velocizzare\n",
    "- verbose=1,               # Mostra il progresso della ricerca\n",
    "- return_train_score=True  # Salva anche i punteggi sul training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607cba8",
   "metadata": {},
   "source": [
    "Sezione 3: Naive Bayes con CountVectorizer\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e25c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(preprocessor):\n",
    "    return Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('bow', CountVectorizer(stop_words=stopwords_setting,\n",
    "                                    tokenizer=custom_tokenizer,\n",
    "                                    token_pattern=None,          # disattiva il tokenizer interno di scikit-learn\n",
    "                                    lowercase=False)),           # Disattiva lowercase automatico: lo gestiamo noi nel tokenizer\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, preproc in {\n",
    "    \"Snowball\": SnowballPreprocessor(),\n",
    "    \"spaCy\": SpacyLemmatizer(),\n",
    "    \"Stanza\": StanzaLemmatizer()\n",
    "}.items():\n",
    "    print(f\"\\n Valutazione con {name}\")\n",
    "    pipeline_nb = build_pipeline(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed55266",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'bow__max_df': [0.7, 0.85, 1.0],         # Importante: per rumore e riduzione dimensionalità\n",
    "    'bow__min_df': [1,],                     # Importante\n",
    "    'bow__ngram_range': [(1,1), (1,2)],      # Importante: cattura sequenze di parole\n",
    "    'clf__alpha': [0.5, 1.0, 2.0],           # Molto importante: smoothing (evita 0 probs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44845ef7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415b7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "Best params: {'bow__max_df': 0.7, 'bow__min_df': 1, 'bow__ngram_range': (1, 1), 'clf__alpha': 0.5}\n",
      "Best Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline_nb, param_grid_nb, cv=2, scoring='recall', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best Recall:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808b0fe",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5c695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes (Bag-of-Words) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb = grid.predict(X_test)\n",
    "print(\"\\n=== Naive Bayes (Bag-of-Words) ===\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f066e3",
   "metadata": {},
   "source": [
    "Sezione 4: BERT con Hugging Face\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00f6aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4daf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", device if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6567d829",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'dbmdz/bert-base-italian-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2) # num labels=2 --> 2 classi: tossico e non tossico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1deea",
   "metadata": {},
   "source": [
    "dbmdz/bert-base-italian-uncased non è adatto per analisi di tono, emotività, emoji, né per distinguere le maiuscole, perché:\n",
    "\n",
    "È uncased → perde le maiuscole (e quindi segnali di urgenza, rabbia o intensità).\n",
    "\n",
    "Usa un tokenizer BERT classico → poco efficace con emoji, simboli, e sequenze di punteggiatura (che nel linguaggio informale hanno valore semantico e pragmalinguistico forte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb4f9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIAO → ['ciao']\n",
      "Ciao → ['ciao']\n",
      "😊 → ['[UNK]']\n",
      "🚀 → ['[UNK]']\n",
      "🆙 → ['[UNK]']\n",
      "... → ['.', '.', '.']\n",
      ". → ['.']\n",
      "! → ['!']\n",
      "!!! → ['!', '!', '!']\n",
      "!? → ['!', '?']\n"
     ]
    }
   ],
   "source": [
    "for s in [\"CIAO\", \"Ciao\", \"😊\", \"🚀\", '🆙','...','.', '!','!!!', '!?']:\n",
    "    tokens = tokenizer.encode(s, add_special_tokens=False)\n",
    "    print(s, \"→\", tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03717d44",
   "metadata": {},
   "source": [
    "Output del tokenizer:\n",
    "- CIAO → ['ciao']\n",
    "- Ciao → ['ciao']\n",
    "- 😊 → ['[UNK]']\n",
    "- 🚀 → ['[UNK]']\n",
    "- 🆙 → ['[UNK]']\n",
    "- ... → ['.', '.', '.']\n",
    "- . → ['.']\n",
    "- ! → ['!']\n",
    "- !!! → ['!', '!', '!']\n",
    "- !? → ['!', '?']\n",
    "\n",
    "Questo non è un buon tokenizer per il nostro caso, perché:\n",
    "- Non riconosce emoji e simboli come token distinti.\n",
    "- Tratta le parole in MAIUSCOLO come normali, perdendo segnali di urla o aggressività.\n",
    "- Non gestisce bene la punteggiatura, trattandola come separatori invece che come elementi significativi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4379f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14d4eae3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "    return Dataset.from_dict({\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': labels\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "727dd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenize_data(X_train, y_train)\n",
    "test_dataset = tokenize_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85f34420",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../out/bart/results'+ \"_\" + timestamp,                # Dove salvare i checkpoint del modello durante il training\n",
    "    num_train_epochs=3,                    # Numero di epoche di addestramento (quante volte scorre tutto il dataset)\n",
    "    per_device_train_batch_size=8,         # Dimensione del batch per il training (per ogni GPU o CPU)\n",
    "    per_device_eval_batch_size=8,          # Dimensione del batch per la valutazione (validation)\n",
    "    learning_rate=2e-5,                    # Tasso di apprendimento: quanto \"velocemente\" il modello aggiorna i pesi\n",
    "    weight_decay=0.01,                     # Regolarizzazione L2 per evitare overfitting\n",
    "    eval_strategy=\"epoch\",                 # Valuta le performance alla fine di ogni epoca\n",
    "    save_strategy=\"epoch\",                 # Salva i pesi del modello alla fine di ogni epoca\n",
    "    logging_dir='./logs',                  # Directory per salvare i log (per TensorBoard, ecc.)\n",
    "    load_best_model_at_end=True            # Ricarica automaticamente il modello con le performance migliori. Se imposti:load_best_model_at_end = False\n",
    "                                           # il modello finale che rimane in memoria sarà quello dell’ultima epoca.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3efec61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    acc = (predictions == torch.tensor(labels)).float().mean().item()\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d4249ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fde21d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.625997</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.618743</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.615734</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BERT (dbmdz/bert-base-italian-uncased) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "print(\"\\n=== BERT (dbmdz/bert-base-italian-uncased) ===\")\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Accuracy: {eval_result['eval_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
